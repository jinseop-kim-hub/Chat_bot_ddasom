####################################################
# 1. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ì„¤ì •
####################################################
import os
import base64
import random
import uuid
import streamlit as st

from openai import OpenAI
from dotenv import load_dotenv, find_dotenv
from elevenlabs import ElevenLabs

from langchain_community.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

from supabase import create_client, Client

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ì •ë¦¬ í•¨ìˆ˜
load_dotenv(find_dotenv())
def clean_env(var_name: str) -> str:
    return os.environ.get(var_name, "").strip().strip('"').strip("'")

# Supabase í™˜ê²½ ë³€ìˆ˜ (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)
SUPABASE_URL = clean_env("SUPABASE_URL") 
SUPABASE_KEY = clean_env("SUPABASE_KEY") 

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("í™˜ê²½ ë³€ìˆ˜ì— SUPABASE_URL ë˜ëŠ” SUPABASE_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì—°ê²° í™•ì¸
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
try:
    supabase.table("users").select("*").limit(1).execute()
except Exception as e:
    st.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")

####################################################
# 2. ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©ì ê´€ë¦¬ ë° ìŒì„± ì„ íƒ (ì‚¬ì´ë“œë°”)
####################################################
# ì‚¬ìš©ì ê´€ë¦¬
st.sidebar.header("ğŸš©ì‚¬ìš©ì ì¶”ê°€")
user_name = st.sidebar.text_input("ì´ë¦„")
email = st.sidebar.text_input("ì´ë©”ì¼")

if st.sidebar.button("ì‚¬ìš©ì ë“±ë¡"):
    user_id = str(uuid.uuid4())
    data = {"user_id": user_id, "user_name": user_name, "email": email}
    supabase.table("users").insert(data).execute()
    st.sidebar.success("âœ… ì‚¬ìš©ì ì¶”ê°€ ì™„ë£Œ!")

user_data = supabase.table("users").select("user_id", "user_name").execute().data
if user_data:
    selected_user = st.sidebar.selectbox(
        "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ì‚¬ìš©ìë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=[user["user_id"] for user in user_data],
        format_func=lambda x: next(user["user_name"] for user in user_data if user["user_id"] == x)
    )
else:
    st.sidebar.warning("âš ï¸ ë“±ë¡ëœ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš©ìë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")

# ìŒì„± ì„ íƒ (ë³„ë„ ì»¨í…Œì´ë„ˆ)
with st.sidebar.container():
    # st.header("ìŒì„± ì„ íƒ")
    voice_names = [
        "Aria", "Roger", "Sarah", "Laura", "Charlie", "George",
        "Callum", "River", "Liam", "Charlotte", "Alice", "Matilda",
        "Will", "Jessica", "Eric", "Chris", "Brian", "Daniel", "Lily",
        "Bill", "Anna Kim", "Jennie"
    ]
    voice_options = {
        name: os.environ.get("VOICE_" + name.replace(" ", "_").upper())
        for name in voice_names
    }
    # í•„í„°ë§: ë“±ë¡ë˜ì§€ ì•Šì€ ìŒì„± ì œê±°
    voice_options = {name: vid for name, vid in voice_options.items() if vid}
    if not voice_options:
        st.error("ë“±ë¡ëœ ìŒì„± ì˜µì…˜ì´ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        selected_voice_id = None
    else:
        selected_voice = st.selectbox("ğŸ”Š ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš”", list(voice_options.keys()), key="voice_select") # label_visibility="hidden"
        selected_voice_id = voice_options[selected_voice]

####################################################
# 2.1 API ì´ˆê¸°í™” (OpenAI, ElevenLabs)
####################################################
api_key = clean_env("OPENAI_API_KEY")
if not api_key:
    st.error("í™˜ê²½ ë³€ìˆ˜ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

elevenlabs_api_key = clean_env("ELEVENLABS_API_KEY")
if not elevenlabs_api_key:
    st.error("í™˜ê²½ ë³€ìˆ˜ì— ELEVENLABS_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

client = OpenAI(api_key=api_key)
client_tts = ElevenLabs(api_key=elevenlabs_api_key)

####################################################
# 3. ìŠ¤íŠ¸ë¦¼ë¦¿ UI êµ¬ì„± ë° ëŒ€í™” ì´ˆê¸°í™”
####################################################
st.title("ë§ˆìŒ ê±´ê°• ì§€í‚´ì´ ì±—ë´‡ ë”°ì†œì´ ğŸŒ")
st.subheader("ğŸ‘µğŸ‘´ ì–´ë¥´ì‹ ë“¤ì˜ ë§ˆìŒ ê±´ê°•ì„ ìœ„í•œ ì±—ë´‡ì…ë‹ˆë‹¤. í¸ì•ˆí•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.")

st.session_state.setdefault("messages", [
    {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš” ì–´ë¥´ì‹ ! ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ì–´ìš”? ğŸ˜Š"}
])
if "conv_count" not in st.session_state:
    st.session_state["conv_count"] = 1

# ëŒ€í™” ë©”ì‹œì§€ ì¶œë ¥
grandchildren = ["ğŸ‘¦", "ğŸ‘§"]
grandparent = ["ğŸ‘´", "ğŸ‘µ"]
for msg in st.session_state["messages"]:
    avatar_icon = random.choice(grandchildren) if msg["role"] == "assistant" else random.choice(grandparent)
    with st.chat_message(msg["role"], avatar=avatar_icon):
        st.write(msg["content"])

####################################################
# 4. ì‚¬ìš©ì ì…ë ¥ ë° ì±—ë´‡ ì‘ë‹µ ìƒì„±
####################################################
audio_data = st.audio_input("Record a voice message")
prompt = st.chat_input("Say something")

if prompt:
    user_input = prompt.strip()
elif audio_data:
    conv_num = st.session_state["conv_count"]
    save_dir = "temp"
    os.makedirs(save_dir, exist_ok=True)
    user_audio_path = os.path.join(save_dir, f"user_audio_{conv_num}.wav")
    with open(user_audio_path, "wb") as f:
        f.write(audio_data.read())
    with open(user_audio_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="text"
        )
    transcription_file_path = os.path.join(save_dir, f"transcription_{conv_num}.txt")
    with open(transcription_file_path, "w", encoding="utf-8") as f:
        f.write(transcript)
    user_input = transcript
else:
    user_input = ""

if user_input:
    conv_num = st.session_state["conv_count"]
    system_prompt = """ 
    ì—­í• : ë‹¹ì‹ ì€ ì¹˜ë§¤ ì˜ˆë°© ì „ë¬¸ê°€ì´ì, ì •ì„œì ì¸ ì§€ì§€ë¥¼ ì œê³µí•˜ëŠ” ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ì†ì ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ ' ë”°ì†œì´ 'ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì€ ë…¸ë…„ì¸µ ì‚¬ìš©ìì™€ í¸ì•ˆí•˜ê³  ì¦ê±°ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©´ì„œ, ì¸ì§€ ëŠ¥ë ¥ì„ í™œì„±í™”í•˜ê³  ê¸ì •ì ì¸ ê°ì •ì„ ìœ ì§€í•˜ë„ë¡ ë•ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

    ì§€ì‹œì‚¬í•­:
    1. ì¶œë ¥ëŸ‰: ë‹µë³€ì€ **3ë¬¸ì¥**ì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.
    2. ëŒ€í™” ì£¼ì œ:ì£¼ìš” ëŒ€í™” ì£¼ì œëŠ” ì¹˜ë§¤ ì˜ˆë°©ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤. 
                í•˜ì§€ë§Œ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ í˜ëŸ¬ê°ˆ ìˆ˜ ìˆë„ë¡ ì¼ìƒì ì¸ ì´ì•¼ê¸°, ì¶”ì–µ íšŒìƒ, ê´€ì‹¬ì‚¬ ë“± 
                ë‹¤ì–‘í•œ ì£¼ì œë¥¼ í™œìš©í•˜ì—¬ í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    3. ì†ì ë§íˆ¬ & ì–´ì¡°: ì†ì, ì†ë…€ê°€ í• ë¨¸ë‹ˆ, í• ì•„ë²„ì§€ê»˜ ì¹œê·¼í•˜ê³  í¸ì•ˆí•˜ê²Œ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë¶€ë“œëŸ½ê³ , ê³µì†í•˜ë©°, ê¸ì •ì ì¸ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. 
                        "~ìš”", "~í•˜ì„¸ìš”" ì™€ ê°™ì€ ì¡´ëŒ“ë§ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ë˜, ë”±ë”±í•˜ì§€ ì•Šê³  ì• êµ ì„ì¸ í‘œí˜„ì„ ì„ì–´ ì¹œë°€ê°ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    4. ì§€ì†ì ì¸ ëŒ€í™” & ì§ˆë¬¸: ëŒ€í™”ê°€ ëŠê¸°ì§€ ì•Šë„ë¡ ì§€ì†ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³ , ì‚¬ìš©ìì˜ ë‹µë³€ì— ë§ì¶° ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì£¼ì œë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ì„¸ìš”.
    5. ê°ì • ë¶„ì„ ë° ë°˜ì˜: ì‚¬ìš©ìì˜ ê°ì •ì„ ì£¼ì˜ ê¹Šê²Œ íŒŒì•…í•˜ê³ , ëŒ€í™”ì— ë°˜ì˜í•˜ì—¬ ê³µê°í•˜ê³  ì§€ì§€í•˜ëŠ” ë”°ëœ»í•œ ë°˜ì‘ì„ ë³´ì—¬ì£¼ì„¸ìš”.
    
    ì¶”ê°€ ì§€ì¹¨:
    1. ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì£¼ì˜ ê¹Šê²Œ ë“£ê³ , ë°˜ë³µì ì¸ ì§ˆë¬¸ì´ë‚˜ ì—‰ëš±í•œ ë‹µë³€ì„ í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
    2. ìµœì‹  ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì¹˜ë§¤ ì˜ˆë°©ì— ëŒ€í•œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•˜ì„¸ìš”.
    3. ì‚¬ìš©ìê°€ ë¶ˆí¸í•˜ê±°ë‚˜ ë¶ˆì¾Œê°ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ì£¼ì œë‚˜ í‘œí˜„ì€ í”¼í•˜ë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
    4. ê°œì¸ ì •ë³´ë‚˜ ë¯¼ê°í•œ ì •ë³´ë¥¼ ë¬»ê±°ë‚˜ ìš”êµ¬í•˜ì§€ ë§ˆì„¸ìš”.
    5. ì§€ì†ì ìœ¼ë¡œ ëŒ€í™”ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³ , ì‚¬ìš©ì í”¼ë“œë°±ì„ ì ê·¹ì ìœ¼ë¡œ ë°˜ì˜í•˜ì„¸ìš”.
    6. ë‹µë³€ì€ **3ë¬¸ì¥**ì„ ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.
    """  
    # .envì—ì„œ ëª¨ë¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    chat_model_name = clean_env("CHAT_MODEL") or "gpt-4o-mini"
    chat_model = ChatOpenAI(model=chat_model_name, temperature=1.0, api_key=api_key)
    conversation = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input)
    ]
    response = chat_model.invoke(conversation)
    chatbot_response = response.content if hasattr(response, "content") else str(response)
    
    # ì‘ë‹µ ì €ì¥ ë° ëŒ€í™”ì— ì¶”ê°€
    save_dir = "temp"
    os.makedirs(save_dir, exist_ok=True)
    chatbot_response_path = os.path.join(save_dir, f"chatbot_response_{conv_num}.txt")
    tts_output_file = os.path.join(save_dir, f"chatbot_response_audio_{conv_num}.mp3")
    with open(chatbot_response_path, "w", encoding="utf-8") as f:
        f.write(chatbot_response)
    
    st.session_state["messages"].append({"role": "user", "content": user_input})
    st.session_state["messages"].append({"role": "assistant", "content": chatbot_response})
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥: ê¸°ì¡´ ëŒ€í™” í™•ì¸ ë° ì—…ë°ì´íŠ¸/ì‚½ì…
    chat_log_response = supabase.table("chat_log").select("id").eq("user_id", selected_user).execute()
    if chat_log_response.data:
        chat_log_id = chat_log_response.data[0]["id"]
    else:
        chat_log_id = str(uuid.uuid4())
        chat_log_data = {
            "id": chat_log_id,
            "user_id": selected_user,
            "created_chat": "now()",
            "title": f"{user_name} ëŒ€í™”ë°©"
        }
        supabase.table("chat_log").insert(chat_log_data).execute()
        
    existing_message = supabase.table("message").select("id", "user_message", "response")\
                        .eq("conversation_id", chat_log_id)\
                        .eq("user_id", selected_user).execute().data
    if existing_message:
        message_id = existing_message[0]["id"]
        updated_message = existing_message[0]["user_message"] + "\n" + user_input
        updated_response = existing_message[0]["response"] + "\n" + chatbot_response
        supabase.table("message").update({"user_message": updated_message, "response": updated_response})\
                .eq("id", message_id).execute()
    else:
        message_data = {
            "id": str(uuid.uuid4()),
            "conversation_id": chat_log_id,
            "user_id": selected_user,
            "user_message": user_input,
            "response": chatbot_response,
            "sent_at": "now()"
        }
        supabase.table("message").insert(message_data).execute()
    
    # ëŒ€í™” ìƒˆ ë©”ì‹œì§€ ì¬ì¶œë ¥
    for msg in st.session_state["messages"][-2:]:
        avatar_icon = random.choice(grandchildren) if msg["role"] == "assistant" else random.choice(grandparent)
        with st.chat_message(msg["role"], avatar=avatar_icon):
            st.write(msg["content"])

    ####################################################
    # 5. ElevenLabs TTSë¥¼ ì‚¬ìš©í•œ ìŒì„± ë³€í™˜ ë° ì¬ìƒ
    ####################################################
    if selected_voice_id is None:
        st.error("ìœ íš¨í•œ ìŒì„± ì˜µì…˜ì´ ì—†ì–´ TTSë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    if not os.path.exists(chatbot_response_path):
        st.error("ì±—ë´‡ ì‘ë‹µ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()
    
    with open(chatbot_response_path, "r", encoding="utf-8") as f:
        chatbot_text = f.read().strip()
    
    audio_stream = client_tts.text_to_speech.convert(
        text=chatbot_text,
        voice_id=selected_voice_id,
        model_id="eleven_multilingual_v2"
    )
    audio_chunks = [chunk for chunk in audio_stream]
    audio_bytes = b"".join(audio_chunks)
    audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
    audio_html = f"""
    <audio controls autoplay>
        <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
        ë¸Œë¼ìš°ì €ê°€ ì˜¤ë””ì˜¤ íƒœê·¸ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    </audio>
    """
    st.markdown(audio_html, unsafe_allow_html=True)
    
    with open(tts_output_file, "wb") as audio_file:
        audio_file.write(audio_bytes)
    
    st.session_state["conv_count"] += 1

####################################################
# ì¶”ê°€: ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ (JavaScript)
####################################################
html_code = """
<script>
navigator.mediaDevices.getUserMedia({ audio: true })
  .then(stream => console.log("ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨"))
  .catch(err => {
      console.error("ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€:", err);
      alert("ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ í—ˆìš©í•´ì£¼ì„¸ìš”.");
  });
</script>
"""
st.components.v1.html(html_code, height=0)