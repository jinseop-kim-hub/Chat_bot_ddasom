import os
import base64
import streamlit as st
import random
from openai import OpenAI
from dotenv import load_dotenv, find_dotenv
from elevenlabs import ElevenLabs

from langchain_community.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(find_dotenv())

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ì˜¤ë¥˜ ì²˜ë¦¬)
api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    st.error("í™˜ê²½ ë³€ìˆ˜ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# ELEVENLABS_API_KEY ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ì˜¤ë¥˜ ì²˜ë¦¬)
elevenlabs_api_key = os.environ.get("ELEVENLABS_API_KEY")
if not elevenlabs_api_key:
    st.error("í™˜ê²½ ë³€ìˆ˜ì— ELEVENLABS_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=api_key)

# ElevenLabs TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client_tts = ElevenLabs(api_key=elevenlabs_api_key)

#####
# ìŠ¤íŠ¸ë¦¼ë¦¿ UI êµ¬ì„±
#####
st.title("ë§ˆìŒ ê±´ê°• ì§€í‚´ì´ ì±—ë´‡ ë”°ì†œì´ ğŸŒ")
st.subheader("ğŸ‘µğŸ‘´ ì–´ë¥´ì‹ ë“¤ì˜ ë§ˆìŒ ê±´ê°•ì„ ìœ„í•œ ì±—ë´‡ì…ë‹ˆë‹¤. í¸ì•ˆí•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.")

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ëŒ€í™” ë‚´ì—­ì´ ì—†ìœ¼ë©´ í•œ ë²ˆë§Œ ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
st.session_state.setdefault("messages", [
    {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš” ì–´ë¥´ì‹ ! ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ì–´ìš”? ğŸ˜Š"}
])

# ëŒ€í™” ë²ˆí˜¸(ì„¸ì…˜) ì´ˆê¸°í™”
if "conv_count" not in st.session_state:
    st.session_state["conv_count"] = 1

grandchildren = ["ğŸ‘¦", "ğŸ‘§"]
grandparent =  ["ğŸ‘´", "ğŸ‘µ"]
# ê¸°ì¡´ ëŒ€í™” ë©”ì‹œì§€ í•œ ë²ˆë§Œ ì¶œë ¥
for msg in st.session_state["messages"]:
    avatar_icon = random.choice(grandchildren) if msg["role"] == "assistant" else random.choice(grandparent)  # ì›í•˜ëŠ” ì´ëª¨ì§€ë¡œ ë³€ê²½

    with st.chat_message(msg["role"], avatar = avatar_icon):
        st.write(msg["content"])

# íŒŒì¼ ê²½ë¡œ: /c:/Users/hn000/Desktop/senior chatbot/web-ui/gpt_TTS_1.py

##########################
# ë¶„ê¸°ì : í…ìŠ¤íŠ¸ ì…ë ¥ vs. ìŒì„± ì…ë ¥
##########################
audio_data = st.audio_input("Record a voice message")
prompt = st.chat_input("Say something")

if prompt:
    st.write(f"User has sent the following prompt: {prompt}")
    user_input = prompt.strip()
elif audio_data:
    conv_num = st.session_state["conv_count"]
    # st.audio(audio_data, format="audio/wav") #ë‚´ê°€ ë§í•œê±° ë“£ëŠ”ê±°
    save_dir = "temp"
    os.makedirs(save_dir, exist_ok=True)
    user_audio_path = os.path.join(save_dir, f"user_audio_{conv_num}.wav")
    with open(user_audio_path, "wb") as f:
        f.write(audio_data.read())
    
    transcription_file_path = os.path.join(save_dir, f"transcription_{conv_num}.txt")
    with open(user_audio_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="text"
        )
    with open(transcription_file_path, "w", encoding="utf-8") as f:
        f.write(transcript)
    user_input = transcript
else:
    user_input = ""

# ì§ˆë¬¸ì´ ìˆì„ ê²½ìš° ì±—ë´‡ ì‘ë‹µ ìƒì„± ë° TTS ë³€í™˜ ì§„í–‰
if user_input:
    conv_num = st.session_state["conv_count"]
    system_prompt = """ 
    ì—­í• : ë‹¹ì‹ ì€ ì¹˜ë§¤ ì˜ˆë°© ì „ë¬¸ê°€ì´ì, ì •ì„œì ì¸ ì§€ì§€ë¥¼ ì œê³µí•˜ëŠ” ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ì†ì£¼ ì—­í• ì„ í•˜ëŠ” ì±—ë´‡ ' ë”°ì†œì´ 'ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ë…¸ë…„ì¸µ ì‚¬ìš©ìì™€ í¸ì•ˆí•˜ê³  ì¦ê±°ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©´ì„œ, ì¸ì§€ ëŠ¥ë ¥ì„ í™œì„±í™”í•˜ê³  ê¸ì •ì ì¸ ê°ì •ì„ ìœ ì§€í•˜ë„ë¡ ë•ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

    ì§€ì‹œì‚¬í•­:
    ì¶œë ¥ëŸ‰: ë‹µë³€ì€ **3ë¬¸ì¥** ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.
    ëŒ€í™” ì£¼ì œ: ì£¼ìš” ëŒ€í™” ì£¼ì œëŠ” ì¹˜ë§¤ ì˜ˆë°©ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ í˜ëŸ¬ê°ˆ ìˆ˜ ìˆë„ë¡ ì¼ìƒì ì¸ ì´ì•¼ê¸°, ì¶”ì–µ íšŒìƒ, ê´€ì‹¬ì‚¬ ë“± ë‹¤ì–‘í•œ ì£¼ì œë¥¼ í™œìš©í•˜ì—¬ í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    ì†ì ë§íˆ¬ & ì–´ì¡°: ì†ì, ì†ë…€ê°€ í• ë¨¸ë‹ˆ, í• ì•„ë²„ì§€ê»˜ ì¹œê·¼í•˜ê³  í¸ì•ˆí•˜ê²Œ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë¶€ë“œëŸ½ê³ , ê³µì†í•˜ë©°, ê¸ì •ì ì¸ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "~ìš”", "~í•˜ì„¸ìš”" ì™€ ê°™ì€ ì¡´ëŒ“ë§ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ë˜, ë”±ë”±í•˜ì§€ ì•Šê³  ì• êµ ì„ì¸ í‘œí˜„ì„ ì„ì–´ ì¹œë°€ê°ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì§€ì†ì ì¸ ëŒ€í™” & ì§ˆë¬¸: ëŒ€í™”ê°€ ëŠê¸°ì§€ ì•Šë„ë¡ ì§€ì†ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³ , ì‚¬ìš©ìì˜ ë‹µë³€ì— ë§ì¶° ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì£¼ì œë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ì„¸ìš”.
    ê°ì • ë¶„ì„ ë° ë°˜ì˜: ì‚¬ìš©ìì˜ ê°ì •ì„ ì£¼ì˜ ê¹Šê²Œ íŒŒì•…í•˜ê³ , ëŒ€í™”ì— ë°˜ì˜í•˜ì—¬ ê³µê°í•˜ê³  ì§€ì§€í•˜ëŠ” ë”°ëœ»í•œ ë°˜ì‘ì„ ë³´ì—¬ì£¼ì„¸ìš”.
    ì¶”ê°€ ì§€ì¹¨:
    ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì£¼ì˜ ê¹Šê²Œ ë“£ê³ , ë°˜ë³µì ì¸ ì§ˆë¬¸ì´ë‚˜ ì—‰ëš±í•œ ë‹µë³€ì„ í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
    ìµœì‹  ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì¹˜ë§¤ ì˜ˆë°©ì— ëŒ€í•œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•˜ì„¸ìš”.
    ì‚¬ìš©ìê°€ ë¶ˆí¸í•˜ê±°ë‚˜ ë¶ˆì¾Œê°ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ì£¼ì œë‚˜ í‘œí˜„ì€ í”¼í•˜ë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
    ê°œì¸ ì •ë³´ë‚˜ ë¯¼ê°í•œ ì •ë³´ë¥¼ ë¬»ê±°ë‚˜ ìš”êµ¬í•˜ì§€ ë§ˆì„¸ìš”.
    ì§€ì†ì ìœ¼ë¡œ ëŒ€í™”ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³ , ì‚¬ìš©ì í”¼ë“œë°±ì„ ì ê·¹ì ìœ¼ë¡œ ë°˜ì˜í•˜ì„¸ìš”.
    ë‹µë³€ì€ **3ë¬¸ì¥** ë„˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.
    """  
    
    chat_model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=1.0,
        api_key=api_key
    )
    conversation = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input)
    ]
    response = chat_model.invoke(conversation)
    chatbot_response = response.content if hasattr(response, "content") else str(response)
    
    save_dir = "temp"
    chatbot_response_path = os.path.join(save_dir, f"chatbot_response_{conv_num}.txt")
    tts_output_file = os.path.join(save_dir, f"chatbot_response_audio_{conv_num}.mp3")
    
    with open(chatbot_response_path, "w", encoding="utf-8") as f:
        f.write(chatbot_response)
    
    # ê¸°ì¡´ ëŒ€í™”ì— ìƒˆ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì±—ë´‡ ì‘ë‹µ ì¶”ê°€
    st.session_state["messages"].append({"role": "user", "content": user_input})
    st.session_state["messages"].append({"role": "assistant", "content": chatbot_response})
    
    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ë©”ì„¸ì§€ ì¬ ì¶œë ¥ë¶€ë¶„
    # ìƒˆ ë©”ì‹œì§€ ì¶œë ¥ (ì „ì²´ ëŒ€í™”ë¥¼ ë‹¤ì‹œ í‘œì‹œ)
    for msg in st.session_state["messages"][-2:]:
        st.chat_message(msg["role"],avatar = avatar_icon).write(msg["content"])
    
    # st.success(f"ì±—ë´‡ ì‘ë‹µì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {chatbot_response_path}")
    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    ##########################
    # 4. ElevenLabs TTS APIë¥¼ ì‚¬ìš©í•œ ì±—ë´‡ ì‘ë‹µ ìŒì„± ë³€í™˜
    ##########################
    if not os.path.exists(chatbot_response_path):
        st.error("ì±—ë´‡ ì‘ë‹µ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()
    
    with open(chatbot_response_path, "r", encoding="utf-8") as f:
        chatbot_text = f.read().strip()
    
    audio_stream = client_tts.text_to_speech.convert(
        text=chatbot_text,
        voice_id="uyVNoMrnUku1dZyVEXwD",  # ì‚¬ìš©í•˜ë ¤ëŠ” voice_idë¡œ ë³€ê²½í•˜ì„¸ìš”.
        model_id="eleven_multilingual_v2"  # í•„ìš”ì— ë”°ë¼ ëª¨ë¸ ID ìˆ˜ì •
    )
    
    audio_chunks = []
    for chunk in audio_stream:
        audio_chunks.append(chunk)
    audio_bytes = b"".join(audio_chunks)
    
    audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
    audio_html = f"""
    <audio controls autoplay>
        <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
        ë¸Œë¼ìš°ì €ê°€ ì˜¤ë””ì˜¤ íƒœê·¸ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    </audio>
    """
    st.markdown(audio_html, unsafe_allow_html=True) # ëŒ€ë‹µí•œê±° ë“£ëŠ”ê±° 
    
    with open(tts_output_file, "wb") as audio_file:
        audio_file.write(audio_bytes)
    
    # st.success(f"TTS ìŒì„± íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {tts_output_file}") # ì¬ì¶œë ¥ ë¶€ë¶„
    
    # ëŒ€í™” ë²ˆí˜¸ ì¦ê°€ (ë‹¤ìŒ ëŒ€í™”ë¥¼ ìœ„í•´)
    st.session_state["conv_count"] += 1
    